import gradio as gr
import pandas as pd
import requests
import json
import os
import torch
import psutil
import logging
import PyPDF2
import threading
import time
from docx import Document
from datetime import datetime

# Configuration API Ollama
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODELS_URL = "http://localhost:11434/api/tags"
LOG_FILE = "nutricoach.log"
API_KEYS = {
    "openai": "TA_CLE_OPENAI",
    "anthropic": "TA_CLE_ANTHROPIC",
    "perplexity": "TA_CLE_PERPLEXITY"
}

stop_event = threading.Event()

# Configuration du logging
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
console = logging.StreamHandler()
console.setLevel(logging.INFO)
formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
console.setFormatter(formatter)
logging.getLogger().addHandler(console)

print("Torch version:", torch.__version__)
print("CUDA disponible:", torch.cuda.is_available())
print("Nombre de GPUs:", torch.cuda.device_count())
if torch.cuda.is_available():
    print("Nom du GPU:", torch.cuda.get_device_name(0))
    print("M√©moire GPU:", torch.cuda.get_device_properties(0).total_memory / 1e9, "GB")

if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"CUDA Capability: {torch.cuda.get_device_capability(i)}")
        print(f"VRAM Total: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} Go")


def log(message):
    """Affiche les logs dans le terminal"""
    print(f"[LOG] {message}")

#Affichage connexion Ollama
def check_connection():
    """V√©rifie la connexion √† Ollama"""
    try:
        response = requests.get(OLLAMA_MODELS_URL, timeout=2)
        if response.status_code == 200:
            return "üü¢ Connect√© √† Ollama"
    except Exception as e:
        return f"üî¥ Ollama non disponible ({str(e)})"
    return "üî¥ Ollama non disponible"

# Fonction pour r√©cup√©rer les mod√®les disponibles
def get_available_models():
    try:
        response = requests.get(OLLAMA_MODELS_URL, timeout=2)
        if response.status_code == 200:
            models = [model["name"] for model in response.json().get("models", [])]
            return models if models else ["Aucun mod√®le disponible"]
    except Exception as e:
        return [f"Erreur de connexion: {str(e)}"]
    return ["Erreur de connexion"]


def stop_operations():
    """D√©clenche un signal pour arr√™ter toutes les op√©rations en cours."""
    global stop_event
    stop_event.set()  # D√©clenche l'arr√™t
    log(f"[{time.strftime('%H:%M:%S')}] üõë Demande d'arr√™t re√ßue. Tentative de lib√©ration des ressources...")

    # Essayer de lib√©rer le mod√®le si possible
    try:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()  # Lib√©rer la m√©moire GPU
            log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ M√©moire GPU lib√©r√©e.")
        else:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ö†Ô∏è Pas de GPU d√©tect√©, pas de m√©moire √† lib√©rer.")

        # Terminer tous les threads actifs
        for thread in threading.enumerate():
            if thread.is_alive() and thread != threading.main_thread():
                log(f"[{time.strftime('%H:%M:%S')}] ‚è≥ Tentative d'arr√™t du thread {thread.name}...")
                thread.join(timeout=1)

        log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Tous les threads ont √©t√© arr√™t√©s.")

    except Exception as e:
        log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur lors de l'arr√™t des op√©rations : {e}")


# Extraction de contenu des fichiers
def extract_content(file_path):
    lines = []
    
    start_time = time.time()
    log(f"[{time.strftime('%H:%M:%S')}] üîÑ D√©but de l'extraction du fichier : {file_path}")

    if stop_event.is_set():
        log(f"[{time.strftime('%H:%M:%S')}] üõë Arr√™t forc√© d√©tect√©. Fin de l'extraction.")
        return "‚ùå Extraction annul√©e."

    try:
        if file_path.endswith(".pdf"):
            log(f"[{time.strftime('%H:%M:%S')}] üìÑ Fichier PDF d√©tect√©, lecture en cours...")
            with open(file_path, "rb") as f:
                reader = PyPDF2.PdfReader(f)
                for page_num, page in enumerate(reader.pages):
                    if stop_event.is_set():
                        log(f"[{time.strftime('%H:%M:%S')}] üõë Arr√™t forc√© pendant la lecture du PDF.")
                        return "‚ùå Extraction annul√©e."
                    text = page.extract_text()
                    if text:
                        lines.append(text)
                    log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Page {page_num + 1} extraite.")

        elif file_path.endswith(".docx"):
            log(f"[{time.strftime('%H:%M:%S')}] üìÑ Fichier DOCX d√©tect√©, lecture en cours...")
            doc = Document(file_path)
            for idx, para in enumerate(doc.paragraphs):
                if stop_event.is_set():
                    log(f"[{time.strftime('%H:%M:%S')}] üõë Arr√™t forc√© pendant la lecture du DOCX.")
                    return "‚ùå Extraction annul√©e."
                lines.append(para.text)
                log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Paragraphe {idx + 1} extrait.")

        elif file_path.endswith(".csv") or file_path.endswith(".xlsx"):
            log(f"[{time.strftime('%H:%M:%S')}] üìä Fichier tabulaire d√©tect√©, lecture en cours...")
            df = load_csv_safely(file_path) if file_path.endswith(".csv") else pd.read_excel(file_path)
            lines.append(df.to_string())

        else:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Type de fichier non pris en charge.")

    except Exception as e:
        log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur lors de l'extraction du fichier : {e}")

    total_time = time.time() - start_time
    log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Extraction termin√©e en {total_time:.2f} secondes.\n")
    return "\n".join(lines)




# Calcul des macros manquantes
def calculate_missing_macros(protein, carbs, fats, kcal):
    try:
        p = float(protein) if protein not in [None, ""] else None
        c = float(carbs) if carbs not in [None, ""] else None
        f = float(fats) if fats not in [None, ""] else None
        k = float(kcal) if kcal not in [None, ""] else None

        if all(v is not None for v in [p, c, f]):
            return p, c, f, p*4 + c*4 + f*9

        if k:
            known_cal = sum([p*4 if p else 0, c*4 if c else 0, f*9 if f else 0])
            remaining = k - known_cal
            missing = sum(1 for v in [p, c, f] if v is None)

            if missing == 1:
                if p is None: p = remaining / 4
                elif c is None: c = remaining / 4
                else: f = remaining / 9
            elif missing == 2:
                if p is not None:
                    c = (remaining * 0.6) / 4
                    f = (remaining * 0.4) / 9
                else:
                    p = (remaining * 0.3) / 4
                    c = (remaining * 0.4) / 4
                    f = (remaining * 0.3) / 9
            elif missing == 3:
                p = (k * 0.3) / 4
                c = (k * 0.4) / 4
                f = (k * 0.3) / 9

            return round(p, 1), round(c, 1), round(f, 1), k

        raise ValueError("Au moins un param√®tre doit √™tre fourni")

    except Exception as e:
        raise ValueError(f"Erreur de calcul: {str(e)}")



def load_csv_safely(file_path):
    """Charge un fichier CSV en d√©tectant automatiquement son format et en √©vitant les erreurs de parsing."""
    
    # üîç √âtape 1 : D√©tecter le s√©parateur
    with open(file_path, "r", encoding="utf-8") as f:
        first_line = f.readline()
    
    possible_separators = [",", ";", "\t", "|"]
    detected_separator = max(possible_separators, key=lambda sep: first_line.count(sep))
    
    print(f"‚úÖ S√©parateur d√©tect√© : {repr(detected_separator)}")

    # üîç √âtape 2 : Lecture du fichier CSV en √©vitant les erreurs
    try:
        df = pd.read_csv(
            file_path, 
            sep=detected_separator, 
            encoding="utf-8",
            engine="python",
            on_bad_lines=lambda line: print(f"‚ö†Ô∏è Ligne ignor√©e : {line}") or None  # Log des lignes corrompues
        )

    except UnicodeDecodeError:
        print("‚ö†Ô∏è Erreur d'encodage d√©tect√©e, tentative avec ISO-8859-1...")
        df = pd.read_csv(file_path, sep=detected_separator, encoding="ISO-8859-1", engine="python")

    print(f"‚úÖ Fichier charg√© avec succ√®s ({df.shape[0]} lignes, {df.shape[1]} colonnes)")
    
    return df


def clean_nutrition_data(json_path):
    """Charge et nettoie les donn√©es JSON."""
    with open(json_path, "r", encoding="utf-8") as file:
        data = json.load(file)

    for item in data:
        for key, value in item.items():
            if isinstance(value, str):
                # Nettoyage des espaces et conversion des nombres
                value = value.strip().replace(",", ".")
                try:
                    item[key] = float(value) if value else None
                except ValueError:
                    pass  # Garder les cha√Ænes de texte inchang√©es

        # ‚úÖ Remplacer les valeurs nulles par 0 ou une valeur par d√©faut
        item["Energie (kcal/100 g)"] = item.get("Energie (kcal/100 g)", 0) or 0
        item["Prot√©ines (g/100 g)"] = item.get("Prot√©ines (g/100 g)", 0) or 0
        item["Glucides (g/100 g)"] = item.get("Glucides (g/100 g)", 0) or 0
        item["Lipides (g/100 g)"] = item.get("Lipides (g/100 g)", 0) or 0
        item["Fibres alimentaires (g/100 g)"] = item.get("Fibres alimentaires (g/100 g)", 0) or 0

    return pd.DataFrame(data)


def generate_nutrition_plan(file, protein, carbs, fats, kcal, diet_type, model, meals):
    """G√©n√®re un plan nutritionnel et log chaque √©tape du traitement."""
    try:
        start_time = time.time()  # D√©but du chronom√®tre
        log(f"[{time.strftime('%H:%M:%S')}] üîÑ D√©but du traitement pour le plan nutritionnel...")

        if stop_event.is_set():
            log(f"[{time.strftime('%H:%M:%S')}] üõë Arr√™t forc√© d√©tect√©. Fin du traitement.")
            return "‚ùå Op√©ration annul√©e."

        # V√©rification du fichier
        if file is None:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur : Aucun fichier fourni.")
            return "‚ùå Veuillez t√©l√©charger un fichier nutritionnel"

        file_path = file.name if hasattr(file, "name") else None
        if not file_path:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur : Fichier non valide.")
            return "‚ùå Fichier non valide"
        if stop_event.is_set():
            log(f"[{time.strftime('%H:%M:%S')}] üõë Arr√™t forc√© d√©tect√©. Fin du traitement.")
            return "‚ùå Op√©ration annul√©e."


        log(f"[{time.strftime('%H:%M:%S')}] üìÇ Fichier re√ßu : {file_path}")

        # V√©rification et conversion des macros
        try:
            protein = float(protein) if protein not in [None, ""] else 0
            carbs = float(carbs) if carbs not in [None, ""] else 0
            fats = float(fats) if fats not in [None, ""] else 0
            kcal = float(kcal) if kcal not in [None, ""] else (protein * 4 + carbs * 4 + fats * 9)
        except ValueError:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur : Valeurs nutritionnelles invalides.")
            return "‚ùå Valeurs nutritionnelles incorrectes"

        log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Macros valid√©es : {protein}g prot√©ines, {carbs}g glucides, {fats}g lipides, {kcal} kcal.")

        # V√©rification du nombre de repas
        try:
            meals = int(meals) if meals not in [None, ""] else None
            if meals is None or meals <= 0:
                raise ValueError("Nombre de repas invalide.")
        except (ValueError, TypeError):
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur : Nombre de repas invalide.")
            return "‚ùå Le nombre de repas est invalide."

        log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Nombre de repas valid√© : {meals} repas/jour.")

        # Lecture du fichier et extraction des aliments
        log(f"[{time.strftime('%H:%M:%S')}] üìä Lecture et analyse du fichier nutritionnel en cours...")
        try:
            if file_path.endswith('.csv'):
                df = load_csv_safely(file_path)
            elif file_path.endswith('.json'):
                df = clean_nutrition_data(file_path)
            elif file_path.endswith('.xlsx'):
                df = pd.read_excel(file_path)
            else:
                log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur : Format de fichier non support√©.")
                return "‚ùå Format de fichier non support√©"
        except Exception as e:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur lors de la lecture du fichier : {e}")
            return f"‚ùå Erreur lors de la lecture du fichier : {str(e)}"

        food_data = df.head(20).to_dict('records')
        log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ {len(food_data)} aliments extraits avec succ√®s.")


        if stop_event.is_set():
            log(f"[{time.strftime('%H:%M:%S')}] üõë Arr√™t forc√© d√©tect√©. Fin du traitement.")
            return "‚ùå Op√©ration annul√©e."

        # Construction du prompt pour l'IA
        print("üìú Construction du prompt pour l'IA...")
        prompt = (
            f"Tu es un assistant expert en nutrition. G√©n√©re un plan alimentaire sur **7 jours** avec exactement **{meals} repas par jour**, en respectant les macros ci-dessous.\n\n"

            f"‚ö†Ô∏è **Objectifs nutritionnels quotidiens** :\n"
            f"- **{kcal:.0f} kcal**\n"
            f"- **{protein:.1f}g prot√©ines** ({protein / meals:.1f}g par repas)\n"
            f"- **{carbs:.1f}g glucides** ({carbs / meals:.1f}g par repas)\n"
            f"- **{fats:.1f}g lipides** ({fats / meals:.1f}g par repas)\n\n"

            f"üìå **Base de donn√©es des aliments autoris√©s** (utilise uniquement ces aliments) :\n"
            f"{json.dumps(food_data, indent=2)}\n\n"

            "üìù **Instructions claires** :\n"
            "- Chaque **jour doit √™tre unique**, aucun repas ne doit √™tre r√©p√©t√©.\n"
            "- Chaque **aliment doit avoir sa quantit√© pr√©cise en grammes**.\n"
            "- Chaque **repas doit respecter les macros du jour**.\n"
            "- Ne rajoute **aucune phrase explicative** en dehors du tableau.\n\n"

            "‚ö†Ô∏è **IMPORTANT :** Affiche UNIQUEMENT le tableau suivant sans explications :\n\n"

            "üü¢ **FORMAT DU TABLEAU ATTENDU** :\n\n"

            "| Jour | Repas       | Aliment           | Quantit√© (g) | √ânergie (kcal) | Prot√©ines (g) | Glucides (g) | Lipides (g) |\n"
            "|------|------------|-------------------|--------------|----------------|---------------|--------------|-------------|\n"
            "| 1    | Petit-d√©j  | Flocons d'avoine  | 50           | 180            | 6             | 30           | 4           |\n"
            "| 1    | D√©jeuner   | Poulet grill√©     | 150          | 230            | 35            | 0            | 5           |\n"
            "| 1    | D√Æner      | Saumon            | 120          | 250            | 25            | 0            | 15          |\n"
            "| 2    | Petit-d√©j  | Yaourt nature     | 150          | 90             | 8             | 7            | 4           |\n"
            "| 2    | D√©jeuner   | Riz complet       | 100          | 130            | 3             | 28           | 1           |\n"
            "| 2    | D√Æner      | Poisson grill√©    | 120          | 180            | 35.5          | 1.8          | 7.2         |\n"
            "...\n\n"

            "Ne modifie **pas** la structure du tableau. **Ne rajoute rien avant ou apr√®s**. Affiche **uniquement** le tableau final, sans explication."
        )



        log(f"[{time.strftime('%H:%M:%S')}] üöÄ Envoi du prompt au LLM...")
        log(f"[{time.strftime('%H:%M:%S')}] üìù Aper√ßu du prompt : {prompt[:200]}... [Tronqu√©]")

        # Chronom√©trage du temps de r√©ponse du LLM
        llm_start_time = time.time()
        response = requests.post(
            OLLAMA_URL,
            json={"model": model, "prompt": prompt, "stream": False}
        )
        llm_duration = time.time() - llm_start_time

        # V√©rification du statut de la r√©ponse
        if response.status_code == 200:
            log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ R√©ponse re√ßue du LLM en {llm_duration:.2f} secondes.")
            result = response.json().get("response", "Aucune r√©ponse obtenue")
        else:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur API : {response.status_code} - {response.text}")
            return f"‚ùå Erreur API : {response.status_code} - {response.text}"

        total_time = time.time() - start_time
        log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Plan nutritionnel g√©n√©r√© en {total_time:.2f} secondes.\n")
        return result

    except Exception as e:
        log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur inattendue : {e}")
        return f"‚ùå Erreur : {str(e)}"


def analyze_document(file, question, model):
    """Analyse un document avec l'Assistant G√©n√©ral et log chaque √©tape."""
    try:
        start_time = time.time()
        log(f"[{time.strftime('%H:%M:%S')}] üîÑ D√©but de l'analyse du document...")

        if file is None:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur : Aucun fichier fourni.")
            return "‚ùå Veuillez t√©l√©charger un fichier."

        file_path = file.name if hasattr(file, "name") else None
        if not file_path:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur : Fichier non valide.")
            return "‚ùå Fichier non valide"

        log(f"[{time.strftime('%H:%M:%S')}] üìÇ Fichier re√ßu : {file_path}")
        log(f"[{time.strftime('%H:%M:%S')}] üìù Question pos√©e : {question}")

        # Extraction du contenu du fichier
        log(f"[{time.strftime('%H:%M:%S')}] üìÑ Extraction du contenu en cours...")
        doc_start_time = time.time()
        extracted_text = extract_content(file_path)
        doc_duration = time.time() - doc_start_time
        log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Contenu extrait en {doc_duration:.2f} secondes.")

        # V√©rification du mod√®le s√©lectionn√©
        if not model or model == "Aucun mod√®le disponible":
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur : Aucun mod√®le s√©lectionn√©.")
            return "‚ùå Veuillez s√©lectionner un mod√®le LLM."


        if stop_event.is_set():
            log(f"[{time.strftime('%H:%M:%S')}] üõë Arr√™t forc√© d√©tect√©. Fin du traitement.")
            return "‚ùå Op√©ration annul√©e."

        # Construction du prompt pour le LLM
        log(f"[{time.strftime('%H:%M:%S')}] üìú Construction du prompt pour l'IA...")
        prompt = f"Document:\n{extracted_text}\n\nQuestion: {question}"

        # Envoi √† l'API Ollama
        log(f"[{time.strftime('%H:%M:%S')}] üöÄ Envoi de la requ√™te au LLM...")
        llm_start_time = time.time()
        response = requests.post(
            OLLAMA_URL,
            json={"model": model, "prompt": prompt, "stream": False}
        )
        llm_duration = time.time() - llm_start_time

        # V√©rification du statut de la r√©ponse
        if response.status_code == 200:
            log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ R√©ponse re√ßue en {llm_duration:.2f} secondes.")
            result = response.json().get("response", "Aucune r√©ponse obtenue")
        else:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur API : {response.status_code} - {response.text}")
            return f"‚ùå Erreur API : {response.status_code} - {response.text}"

        total_time = time.time() - start_time
        log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Analyse du document termin√©e en {total_time:.2f} secondes.\n")
        return result

    except Exception as e:
        log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur inattendue : {e}")
        return f"‚ùå Erreur : {str(e)}"


def query_llm(prompt, model, provider, api_key):
    """Envoie le prompt au LLM choisi (Ollama en local ou API externe)."""
    log(f"[{time.strftime('%H:%M:%S')}] üîÑ Envoi du prompt au LLM ({provider})...")

    start_time = time.time()

    try:
        if provider == "Ollama (local)":
            url = OLLAMA_URL
            payload = {"model": model, "prompt": prompt, "stream": False}
            headers = {}
        elif provider == "OpenAI":
            url = "https://api.openai.com/v1/completions"
            payload = {
                "model": model,
                "prompt": prompt,
                "max_tokens": 1000,
                "temperature": 0.7
            }
            headers = {"Authorization": f"Bearer {api_key}"}
        elif provider == "Anthropic":
            url = "https://api.anthropic.com/v1/complete"
            payload = {
                "model": model,
                "prompt": f"\n\nHuman: {prompt}\n\nAssistant:",
                "max_tokens_to_sample": 1000
            }
            headers = {
                "x-api-key": api_key,
                "Content-Type": "application/json"
            }
        elif provider == "Perplexity":
            url = "https://api.perplexity.ai/v1/chat/completions"
            payload = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 1000,
                "temperature": 0.7
            }
            headers = {"Authorization": f"Bearer {api_key}"}
        else:
            return "‚ùå Fournisseur IA non pris en charge."

        response = requests.post(url, json=payload, headers=headers)
        duration = time.time() - start_time

        if response.status_code == 200:
            log(f"[{time.strftime('%H:%M:%S')}] ‚úÖ R√©ponse re√ßue en {duration:.2f} secondes.")
            return response.json().get("choices", [{}])[0].get("text", "R√©ponse vide").strip()
        else:
            log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur API : {response.status_code} - {response.text}")
            return f"‚ùå Erreur API : {response.status_code} - {response.text}"

    except Exception as e:
        log(f"[{time.strftime('%H:%M:%S')}] ‚ùå Erreur lors de l'interrogation de l'IA : {str(e)}")
        return f"‚ùå Erreur lors de l'interrogation de l'IA : {str(e)}"


# Interface Gradio
with gr.Blocks(title="üëª IvGhost RAG tool", theme=gr.themes.Soft()) as app:
    gr.Markdown("# RAG AI Tool")
    connection_status = gr.Markdown(value=check_connection(), elem_id="status")
    refresh_button = gr.Button("üîÑ V√©rifier connexion")
    refresh_button.click(lambda: check_connection(), outputs=connection_status)

    model_selector = gr.Dropdown(
        label="Mod√®le LLM (Ollama uniquement)",
        choices=get_available_models(),
        interactive=True
    )
    llm_provider = gr.Dropdown(
        label="Fournisseur IA",
        choices=["Ollama (local)", "OpenAI", "Anthropic", "Perplexity"],
        value="Ollama (local)",
        interactive=True
    )
    api_key_input = gr.Textbox(label="üîë Cl√© API (si externe)", type="password", interactive=True)

    stop_button = gr.Button("üõë Arr√™ter toutes les op√©rations")
    stop_button.click(stop_operations)

    # ‚úÖ FIX: Move `gr.Row()` inside `gr.Blocks()`
    with gr.Row():
        model_selector = gr.Dropdown(
            label="Mod√®le LLM",
            choices=get_available_models(),
            interactive=True
        )
        refresh_model_button = gr.Button("üîÑ Actualiser les mod√®les")
        refresh_model_button.click(
            lambda: gr.Dropdown.update(choices=get_available_models()),
            outputs=model_selector
        )

    with gr.Tabs():
        with gr.Tab("üí¨ Assistant G√©n√©ral"):
            gr.Markdown("## Analysez vos documents")
            with gr.Row():
                doc_input = gr.File(label="Document (PDF/CSV/Excel)")
                question_input = gr.Textbox(label="Question", lines=3)

            doc_output = gr.Textbox(label="R√©ponse", interactive=False)
            gr.Button("üîç Analyser").click(
                analyze_document,
                inputs=[doc_input, question_input, model_selector],
                outputs=doc_output
            )

        with gr.Tab("üçé Assistant Nutrition Intelligent"):
            with gr.Row():
                file_input = gr.File(label="Base de donn√©es alimentaire", file_types=[".csv", ".json", ".xlsx"])
                with gr.Column():
                    protein_input = gr.Number(label="Prot√©ines (g/jour)", interactive=True)
                    carbs_input = gr.Number(label="Glucides (g/jour)", interactive=True)
                    fats_input = gr.Number(label="Lipides (g/jour)", interactive=True)
                    kcal_input = gr.Number(label="Calories cibles", interactive=True)
                    meals_input = gr.Number(label="Nombre de repas/jour", interactive=True, precision=0)
                    diet_type_input = gr.Dropdown(["Standard", "V√©g√©tarien", "Vegan", "C√©tog√®ne"], value="Standard", label="Type de r√©gime")

            output = gr.Markdown()
            gr.Button("üöÄ G√©n√©rer le plan").click(
                generate_nutrition_plan,
                inputs=[file_input, protein_input, carbs_input, fats_input, kcal_input, diet_type_input, model_selector, meals_input],
                outputs=output
            )

if __name__ == "__main__":
    app.launch(server_port=7860)
