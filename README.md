==================================================
     Assistant RAG Local avec Ollama (Windows/WSL)
==================================================
Application pour interroger des mod√®les IA locaux (Llama3, DeepSeek, Mistral) 
avec analyse de documents PDF/Word/Excel.

‚ñ†‚ñ†‚ñ† Pr√©requis ‚ñ†‚ñ†‚ñ†
- Windows 10/11 avec WSL 2 activ√©
- 8 Go de RAM minimum
- Python 3.9+ install√© https://www.python.org/downloads/release/python-3120/

‚ñ†‚ñ†‚ñ† Installation ‚ñ†‚ñ†‚ñ†

Pr√©-config : Activer Hyper-V , Virtual machine plateforme) et sous-syst√®me windows pour linux dans :

Param√®tres / Syst√®me / Fonctionnalit√©s facultatives / plus de fonctionnalit√©s Windows

1. Activer WSL (PowerShell Admin) :
----------------------------------
wsl --install
wsl --set-default-version 2

2. Installer Ollama dans WSL :
------------------------------
Dans le terminal Ubuntu/WSL :
curl -fsSL https://ollama.com/install.sh | sh

3. D√©pendances Python (PowerShell/Windows) :
------------------------------------
dans ce dossier ; clic droit (dans le vide); ouvrir terminal puis : 

python -m venv venv
.\venv\Scripts\activate

python.exe -m pip install --upgrade pip

python -m pip install --upgrade pip setuptools wheel

pip install -r requirements.txt


- Si vous avez un GPU Nvidia : 

pip install torch==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121

- Si vous n'avez pas de GPU Nvidia :

pip install torch==2.5.1+cpu


‚ñ†‚ñ†‚ñ† Configuration R√©seau ‚ñ†‚ñ†‚ñ†
(PowerShell Admin - √Ä faire une fois)
-------------------------------------
wsl --shutdown
wsl
sudo apt update && sudo apt install net-tools
sudo sysctl -w net.ipv4.conf.all.route_localnet=1

‚ñ†‚ñ†‚ñ† Utilisation ‚ñ†‚ñ†‚ñ†

1. D√©marrer Ollama (dans WSL) :
-------------------------------
ollama serve

2. Installer un mod√®le (nouveau terminal WSL) :
----------------------------------------------
ollama pull llama3.2 ou autres LLM √† voir sur ollama.com

3. Lancer l'application (PowerShell) :
-------------------------------------
.\venv\Scripts\activate
python Rag_tool_Ivghost.py

ou

Double-clic sur le fichier start.bat 

‚ñ†‚ñ†‚ñ† D√©pannage ‚ñ†‚ñ†‚ñ†

‚ñ∫ Probl√®me : "Erreur de connexion √† Ollama"
Solution :
1. V√©rifier que 'ollama serve' tourne dans WSL
2. Ex√©cuter dans PowerShell Admin :
   New-NetFirewallRule -DisplayName "Ollama" -Direction Inbound -LocalPort 11434 -Protocol TCP -Action Allow

‚ñ∫ Probl√®me : "Aucun mod√®le d√©tect√©"
Solution :
1. Dans WSL : ollama list
2. Rafra√Æchir avec le bouton üîÑ dans l'interface
3. Red√©marrer WSL : wsl --shutdown

‚ñ†‚ñ†‚ñ† Notes ‚ñ†‚ñ†‚ñ†
- Formats support√©s : .pdf, .docx, .xlsx, .txt
- Taille max fichier : 50 Mo
- Mod√®les recommand√©s : 
  * deepseek-r1 (meilleure performance)
  * llama3.1 (√©quilibre vitesse/pr√©cision)
  * mistral (l√©ger)
  * llama3.2 (tr√®s l√©ger, moins performant)
